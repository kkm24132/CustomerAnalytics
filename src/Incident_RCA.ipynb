{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITOps Analytics\n",
    "\n",
    "##  UC: Incident Root Cause Analysis \n",
    "\n",
    "Incident Reports in ITOps usually states the symptoms. Identifying the root cause of the symptom quickly is a key determinant to reducing resolution times and improving user satisfaction. This is a sample use case to demonstrate ML/DL capability based solution using sample data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get desired libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.7.7\n",
      "Tensorflow Version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "#Install all related packages. If you find additional packages missing, please follow the same technique.\n",
    "\n",
    "import sys # For using system function variables\n",
    "import os # For using OS related functions\n",
    "#!conda install --yes --prefix {sys.prefix} pandas tensorflow scikit-learn --> Execute this only in case your desired packages are not installed\n",
    "\n",
    "from platform import python_version #Check for Python version installed on the environment\n",
    "print(\"Python Version: \" + python_version())\n",
    "\n",
    "import tensorflow as tf #Check for tensorflow version installed on the environment\n",
    "print(\"Tensorflow Version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the directory path\n",
    "cwd = os.getcwd()\n",
    "\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Incident Data\n",
    "\n",
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID              int64\n",
      "CPU_LOAD        int64\n",
      "MEMORY_LOAD     int64\n",
      "DELAY           int64\n",
      "ERROR_1000      int64\n",
      "ERROR_1001      int64\n",
      "ERROR_1002      int64\n",
      "ERROR_1003      int64\n",
      "ROOT_CAUSE     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CPU_LOAD</th>\n",
       "      <th>MEMORY_LOAD</th>\n",
       "      <th>DELAY</th>\n",
       "      <th>ERROR_1000</th>\n",
       "      <th>ERROR_1001</th>\n",
       "      <th>ERROR_1002</th>\n",
       "      <th>ERROR_1003</th>\n",
       "      <th>ROOT_CAUSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NETWORK_DELAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  CPU_LOAD  MEMORY_LOAD  DELAY  ERROR_1000  ERROR_1001  ERROR_1002  \\\n",
       "0   1         0            0      0           0           1           0   \n",
       "1   2         0            0      0           0           0           0   \n",
       "2   3         0            1      1           0           0           1   \n",
       "3   4         0            1      0           1           1           0   \n",
       "4   5         1            1      0           1           0           1   \n",
       "\n",
       "   ERROR_1003     ROOT_CAUSE  \n",
       "0           1         MEMORY  \n",
       "1           1         MEMORY  \n",
       "2           1         MEMORY  \n",
       "3           1         MEMORY  \n",
       "4           0  NETWORK_DELAY  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import os\n",
    "#import tensorflow as tf\n",
    "\n",
    "#Load the data file into a Pandas Dataframe\n",
    "symptom_data = pd.read_csv(\"root_cause_analysis.csv\")\n",
    "\n",
    "#Explore the data loaded\n",
    "print(symptom_data.dtypes)\n",
    "symptom_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CPU_LOAD</th>\n",
       "      <th>MEMORY_LOAD</th>\n",
       "      <th>DELAY</th>\n",
       "      <th>ERROR_1000</th>\n",
       "      <th>ERROR_1001</th>\n",
       "      <th>ERROR_1002</th>\n",
       "      <th>ERROR_1003</th>\n",
       "      <th>ROOT_CAUSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DATABASE_ISSUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>992</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DATABASE_ISSUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DATABASE_ISSUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DATABASE_ISSUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NETWORK_DELAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MEMORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NETWORK_DELAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DATABASE_ISSUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  CPU_LOAD  MEMORY_LOAD  DELAY  ERROR_1000  ERROR_1001  ERROR_1002  \\\n",
       "990   991         1            1      0           1           1           1   \n",
       "991   992         1            0      0           1           1           1   \n",
       "992   993         0            0      0           0           0           0   \n",
       "993   994         1            1      0           0           1           0   \n",
       "994   995         0            1      1           0           1           0   \n",
       "995   996         0            0      0           0           0           0   \n",
       "996   997         0            0      0           1           0           0   \n",
       "997   998         1            1      1           0           0           0   \n",
       "998   999         0            1      1           1           1           0   \n",
       "999  1000         1            0      0           0           1           1   \n",
       "\n",
       "     ERROR_1003      ROOT_CAUSE  \n",
       "990           0  DATABASE_ISSUE  \n",
       "991           0  DATABASE_ISSUE  \n",
       "992           1  DATABASE_ISSUE  \n",
       "993           1          MEMORY  \n",
       "994           0          MEMORY  \n",
       "995           1  DATABASE_ISSUE  \n",
       "996           0   NETWORK_DELAY  \n",
       "997           0          MEMORY  \n",
       "998           0   NETWORK_DELAY  \n",
       "999           0  DATABASE_ISSUE  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptom_data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, if you look at above sample dataset above, input features and target are as follows:\n",
    "\n",
    "Input Features: ID, CPU_LOAD, MEMORY_LOAD, DELAY, ERROR_1000, ERROR_1001, ERROR_1002, ERROR_1003\n",
    "\n",
    "Target: ROOT_CAUSE\n",
    "    \n",
    "Problem Type: Multi class classification\n",
    "\n",
    "Obviously, one can use any dataset. Intent here is to get a feel of the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert  data\n",
    "\n",
    "Input data needs to be converted to formats that can be consumed by ML/DL algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature variables : (1000, 7)\n",
      "Shape of target variable : (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# We should convert data to formats that can be consumed by Keras as Keras only consumes NumPy arrays\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# ROOT_CAUSE column is a text attribute. Hence we need to convert it into a numeric value\n",
    "# We have used label_encoder from scikit learn to transform the ROOT_CAUSE into a numeric value.\n",
    "# Since ROOT_CAUSE is our TARGET (i.e y value), it should not be used for input features such as x1, x2, x3 etc\n",
    "# Ref: we can check here for more details for our learning around LabelEncoder() - https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "symptom_data['ROOT_CAUSE'] = label_encoder.fit_transform(symptom_data['ROOT_CAUSE'])\n",
    "\n",
    "# Convert Pandas DataFrame to a numpy vector array using to_numpy() function\n",
    "np_symptom = symptom_data.to_numpy().astype(float)\n",
    "\n",
    "# Separate training attributes X_train into X_train array\n",
    "# Extract the feature variables (X)\n",
    "X_train = np_symptom[:,1:8]\n",
    "\n",
    "#We need to extract the target variable (Y) in Y_train\n",
    "Y_train=np_symptom[:,8]\n",
    "#Then we need to use the one-hot-encoding for this categorical variable for it to be consumed by Keras.\n",
    "#Here we are using utils.to_categorical function within tf.keras\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train,3)\n",
    "\n",
    "print(\"Shape of feature variables :\", X_train.shape)\n",
    "print(\"Shape of target variable :\",Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the Model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 818us/sample - loss: 1.0216 - accuracy: 0.6313 - val_loss: 0.9474 - val_accuracy: 0.7700\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 0.8580 - accuracy: 0.8050 - val_loss: 0.8019 - val_accuracy: 0.8200\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.7041 - accuracy: 0.8138 - val_loss: 0.6745 - val_accuracy: 0.8100\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.5746 - accuracy: 0.8163 - val_loss: 0.5847 - val_accuracy: 0.8200\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.4907 - accuracy: 0.8200 - val_loss: 0.5479 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 0.4524 - accuracy: 0.8325 - val_loss: 0.5335 - val_accuracy: 0.7900\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.4359 - accuracy: 0.8375 - val_loss: 0.5269 - val_accuracy: 0.8200\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.4270 - accuracy: 0.8350 - val_loss: 0.5340 - val_accuracy: 0.8100\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 27us/sample - loss: 0.4193 - accuracy: 0.8525 - val_loss: 0.5229 - val_accuracy: 0.8100\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.4123 - accuracy: 0.8550 - val_loss: 0.5209 - val_accuracy: 0.8300\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.4105 - accuracy: 0.8525 - val_loss: 0.5125 - val_accuracy: 0.8100\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 0.4031 - accuracy: 0.8562 - val_loss: 0.5214 - val_accuracy: 0.7900\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 0.3980 - accuracy: 0.8562 - val_loss: 0.5085 - val_accuracy: 0.7900\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 0.3908 - accuracy: 0.8537 - val_loss: 0.5121 - val_accuracy: 0.8300\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.3885 - accuracy: 0.8550 - val_loss: 0.5141 - val_accuracy: 0.8300\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 22us/sample - loss: 0.3860 - accuracy: 0.8637 - val_loss: 0.5007 - val_accuracy: 0.7800\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 0.3792 - accuracy: 0.8562 - val_loss: 0.5102 - val_accuracy: 0.8100\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.3738 - accuracy: 0.8662 - val_loss: 0.5026 - val_accuracy: 0.8100\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 0.3699 - accuracy: 0.8550 - val_loss: 0.5031 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 0.3648 - accuracy: 0.8662 - val_loss: 0.5009 - val_accuracy: 0.8100\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense-Layer-1 (Dense)        (None, 128)               1024      \n",
      "_________________________________________________________________\n",
      "Dense-Layer-2 (Dense)        (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "Final (Dense)                (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 17,923\n",
      "Trainable params: 17,923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get required libraries for building model with Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#Hyper parameter tuning specification consideration\n",
    "#Setup Training Parameters\n",
    "EPOCHS=20                     # no of iterations\n",
    "BATCH_SIZE=100                # we can set it anything..depending on total number of records, this will segregate in chunks\n",
    "VERBOSE=1                     # we can view the details of model training\n",
    "OUTPUT_CLASSES=len(label_encoder.classes_) # setting to target variables such as ROOT_CAUSE as output class\n",
    "N_HIDDEN=128                  # hidden layer size of 128\n",
    "VALIDATION_SPLIT=0.2          # we set this much percentage to be validation data\n",
    "\n",
    "#Create a Keras sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Add a Dense Layer with ReLu activation (Rectified Linear Unit)\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                             input_shape=(7,),\n",
    "                              name='Dense-Layer-1',\n",
    "                              activation='relu'))\n",
    "\n",
    "#Add a second dense layer similar to above configuration layer\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                              name='Dense-Layer-2',\n",
    "                              activation='relu'))\n",
    "\n",
    "#Add a 3rd layer as softmax layer for categorial prediction\n",
    "model.add(keras.layers.Dense(OUTPUT_CLASSES,\n",
    "                             name='Final',\n",
    "                             activation='softmax'))\n",
    "\n",
    "#We then compile the model, using Adam optimizer and loss function set as categorical_crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Build / Fit the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicting Root Causes\n",
    "\n",
    "Now that we have built the model, we will use that pre-trained model to predict for a new incident (both for a single incident and also for multiple incidents in a batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATABASE_ISSUE']\n"
     ]
    }
   ],
   "source": [
    "#Pass individual flags to Predict the root cause for a new incident\n",
    "CPU_LOAD = 1\n",
    "MEMORY_LOAD = 0\n",
    "DELAY = 0\n",
    "ERROR_1000 = 1\n",
    "ERROR_1001 = 1\n",
    "ERROR_1002 = 0\n",
    "ERROR_1003 = 1\n",
    "\n",
    "# Will provide an array to the model's predict_classes function\n",
    "prediction = model.predict_classes([[CPU_LOAD,MEMORY_LOAD,DELAY,ERROR_1000,ERROR_1001,ERROR_1002,ERROR_1003]])\n",
    "\n",
    "# Then translate the numeric value into a label using inverse transform function on the encoder\n",
    "print(label_encoder.inverse_transform(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATABASE_ISSUE' 'NETWORK_DELAY' 'MEMORY' 'DATABASE_ISSUE'\n",
      " 'DATABASE_ISSUE']\n"
     ]
    }
   ],
   "source": [
    "# Predicting as a Batch\n",
    "# This is much more effective\n",
    "# We create array of arrays\n",
    "print(label_encoder.inverse_transform(\n",
    "        model.predict_classes([[1,0,0,0,1,1,0],\n",
    "                                [0,1,1,1,0,0,0],\n",
    "                                [1,1,0,1,1,0,1],\n",
    "                                [0,0,0,0,0,1,0],\n",
    "                                [1,0,1,0,1,1,1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
